{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a084eb5c",
   "metadata": {},
   "source": [
    "As a beginner, you might only know a single way to load data (normally in CSV) which is to read it using pandas.read_csv function. It is one of the most mature and strong functions, but other ways are a lot helpful and will definitely come in handy sometimes.\n",
    "The ways that I am going to discuss are:\n",
    "Manual function\n",
    "loadtxt function\n",
    "genfromtxtf unction\n",
    "read_csv function\n",
    "Pickle\n",
    "The dataset that we are going to use to load data can be found here. It is named as 100-Sales-Records.\n",
    "Imports\n",
    "We will use Numpy, Pandas, and Pickle packages so import them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5fb79ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febac916",
   "metadata": {},
   "source": [
    "1. Manual Function\n",
    "This is the most difficult, as you have to design a custom function, which can load data for you. You have to deal with Python’s normal filing concepts and using that you have to read a .csv file.\n",
    "Let’s do that on 100 Sales Records file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2d1c8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv(filepath):\n",
    "    data =  []\n",
    "    col = []\n",
    "    checkcol = False\n",
    "    with open(filepath) as f:\n",
    "        for val in f.readlines():\n",
    "            val = val.replace(\"\\n\",\"\")\n",
    "            val = val.split(',')\n",
    "            if checkcol is False:\n",
    "                col = val\n",
    "                checkcol = True\n",
    "            else:\n",
    "                data.append(val)\n",
    "    df = pd.DataFrame(data=data, columns=col)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4cb7f6",
   "metadata": {},
   "source": [
    "Hmmm, What is this????? Seems a bit complex code!!!! Let’s break it step by step so you know what is happening and you can apply similar logic to read a .csv file of your own.\n",
    "\n",
    "Here, I have created a load_csv a function that takes in as an argument the path of the file you want to read.\n",
    "\n",
    "I have a list named as data which is going to have my data of CSV file, and another list col which is going to have my column names. Now after inspecting the csv manually, I know that my column names are in the first row, so in my first iteration, I have to store the data of the first row in col and rest rows in data.\n",
    "\n",
    "To check the first iteration, I have used a Boolean Variable named as checkcol which is False, and when it is false in the first iteration, it stores the data of first-line in col and then it sets checkcol to True, so we will deal with data list and store rest of values in data list.\n",
    "\n",
    "Logic\n",
    "\n",
    "The main logic here is that I have iterated in the file, using readlines() a function in Python. This function returns a list that contains all the lines inside a file.\n",
    "\n",
    "When reading through headlines, it detects a new line as \\n character, which is line terminating character, so in order to remove it, I have used str.replace function.\n",
    "\n",
    "As it is a .csv file, so I have to separate things based on commas so I will split the string on a , using string.split(','). For the first iteration, I will store the first row, which contains the column names in a list known as col. And then I will append all my data in my list known as data.\n",
    "\n",
    "To read the data more beautifully, I have returned it as a dataframe format because it is easier to read a dataframe as compared to a numpy array or python’s list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbe5632d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              Region                Country        Item Type  \\\n",
      "0              Australia and Oceania                 Tuvalu        Baby Food   \n",
      "1  Central America and the Caribbean                Grenada           Cereal   \n",
      "2                             Europe                 Russia  Office Supplies   \n",
      "3                 Sub-Saharan Africa  Sao Tome and Principe           Fruits   \n",
      "4                 Sub-Saharan Africa                 Rwanda  Office Supplies   \n",
      "\n",
      "  Sales Channel Order Priority Order Date   Order ID  Ship Date Units Sold  \\\n",
      "0       Offline              H  5/28/2010  669165933  6/27/2010       9925   \n",
      "1        Online              C  8/22/2012  963881480  9/15/2012       2804   \n",
      "2       Offline              L   5/2/2014  341417157   5/8/2014       1779   \n",
      "3        Online              C  6/20/2014  514321792   7/5/2014       8102   \n",
      "4       Offline              L   2/1/2013  115456712   2/6/2013       5062   \n",
      "\n",
      "  Unit Price Unit Cost Total Revenue  Total Cost Total Profit  \n",
      "0     255.28    159.42    2533654.00  1582243.50    951410.50  \n",
      "1     205.70    117.11     576782.80   328376.44    248406.36  \n",
      "2     651.21    524.96    1158502.59   933903.84    224598.75  \n",
      "3       9.33      6.92      75591.66    56065.84     19525.82  \n",
      "4     651.21    524.96    3296425.02  2657347.52    639077.50  \n"
     ]
    }
   ],
   "source": [
    "myData = load_csv('./100 Sales Records.csv')\n",
    "print(myData.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91c94ac",
   "metadata": {},
   "source": [
    "Pros and Cons\n",
    "\n",
    "The important benefit is that you have all the flexibility and control over the file structure and you can read in whatever format and way you want and store it.\n",
    "\n",
    "You can also read the files which do not have a standard structure using your own logic.\n",
    "\n",
    "Important drawbacks of it are that it is complex to write especially for standard types of files because they can easily be read. You have to hard code the logic which requires trial and error.\n",
    "\n",
    "You should only use it when the file is not in a standard format or you want flexibility and reading the file in a way that is not available through libraries.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec6717f",
   "metadata": {},
   "source": [
    "2. Pandas.read_csv()\n",
    "Pandas is a very popular data manipulation library, and it is very commonly used. One of it’s very important and mature functions is read_csv() which can read any .csv file very easily and help us manipulate it. Let’s do it on our 100-Sales-Record dataset.\n",
    "This function is very popular due to its ease of use. You can compare it with our previous codes, and you can check it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "482dc2e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Region</th>\n",
       "      <th>Country</th>\n",
       "      <th>Item Type</th>\n",
       "      <th>Sales Channel</th>\n",
       "      <th>Order Priority</th>\n",
       "      <th>Order Date</th>\n",
       "      <th>Order ID</th>\n",
       "      <th>Ship Date</th>\n",
       "      <th>Units Sold</th>\n",
       "      <th>Unit Price</th>\n",
       "      <th>Unit Cost</th>\n",
       "      <th>Total Revenue</th>\n",
       "      <th>Total Cost</th>\n",
       "      <th>Total Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Australia and Oceania</td>\n",
       "      <td>Tuvalu</td>\n",
       "      <td>Baby Food</td>\n",
       "      <td>Offline</td>\n",
       "      <td>H</td>\n",
       "      <td>5/28/2010</td>\n",
       "      <td>669165933</td>\n",
       "      <td>6/27/2010</td>\n",
       "      <td>9925</td>\n",
       "      <td>255.28</td>\n",
       "      <td>159.42</td>\n",
       "      <td>2533654.00</td>\n",
       "      <td>1582243.50</td>\n",
       "      <td>951410.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Central America and the Caribbean</td>\n",
       "      <td>Grenada</td>\n",
       "      <td>Cereal</td>\n",
       "      <td>Online</td>\n",
       "      <td>C</td>\n",
       "      <td>8/22/2012</td>\n",
       "      <td>963881480</td>\n",
       "      <td>9/15/2012</td>\n",
       "      <td>2804</td>\n",
       "      <td>205.70</td>\n",
       "      <td>117.11</td>\n",
       "      <td>576782.80</td>\n",
       "      <td>328376.44</td>\n",
       "      <td>248406.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Europe</td>\n",
       "      <td>Russia</td>\n",
       "      <td>Office Supplies</td>\n",
       "      <td>Offline</td>\n",
       "      <td>L</td>\n",
       "      <td>5/2/2014</td>\n",
       "      <td>341417157</td>\n",
       "      <td>5/8/2014</td>\n",
       "      <td>1779</td>\n",
       "      <td>651.21</td>\n",
       "      <td>524.96</td>\n",
       "      <td>1158502.59</td>\n",
       "      <td>933903.84</td>\n",
       "      <td>224598.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sub-Saharan Africa</td>\n",
       "      <td>Sao Tome and Principe</td>\n",
       "      <td>Fruits</td>\n",
       "      <td>Online</td>\n",
       "      <td>C</td>\n",
       "      <td>6/20/2014</td>\n",
       "      <td>514321792</td>\n",
       "      <td>7/5/2014</td>\n",
       "      <td>8102</td>\n",
       "      <td>9.33</td>\n",
       "      <td>6.92</td>\n",
       "      <td>75591.66</td>\n",
       "      <td>56065.84</td>\n",
       "      <td>19525.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sub-Saharan Africa</td>\n",
       "      <td>Rwanda</td>\n",
       "      <td>Office Supplies</td>\n",
       "      <td>Offline</td>\n",
       "      <td>L</td>\n",
       "      <td>2/1/2013</td>\n",
       "      <td>115456712</td>\n",
       "      <td>2/6/2013</td>\n",
       "      <td>5062</td>\n",
       "      <td>651.21</td>\n",
       "      <td>524.96</td>\n",
       "      <td>3296425.02</td>\n",
       "      <td>2657347.52</td>\n",
       "      <td>639077.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Region                Country        Item Type  \\\n",
       "0              Australia and Oceania                 Tuvalu        Baby Food   \n",
       "1  Central America and the Caribbean                Grenada           Cereal   \n",
       "2                             Europe                 Russia  Office Supplies   \n",
       "3                 Sub-Saharan Africa  Sao Tome and Principe           Fruits   \n",
       "4                 Sub-Saharan Africa                 Rwanda  Office Supplies   \n",
       "\n",
       "  Sales Channel Order Priority Order Date   Order ID  Ship Date  Units Sold  \\\n",
       "0       Offline              H  5/28/2010  669165933  6/27/2010        9925   \n",
       "1        Online              C  8/22/2012  963881480  9/15/2012        2804   \n",
       "2       Offline              L   5/2/2014  341417157   5/8/2014        1779   \n",
       "3        Online              C  6/20/2014  514321792   7/5/2014        8102   \n",
       "4       Offline              L   2/1/2013  115456712   2/6/2013        5062   \n",
       "\n",
       "   Unit Price  Unit Cost  Total Revenue  Total Cost  Total Profit  \n",
       "0      255.28     159.42     2533654.00  1582243.50     951410.50  \n",
       "1      205.70     117.11      576782.80   328376.44     248406.36  \n",
       "2      651.21     524.96     1158502.59   933903.84     224598.75  \n",
       "3        9.33       6.92       75591.66    56065.84      19525.82  \n",
       "4      651.21     524.96     3296425.02  2657347.52     639077.50  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdDf = pd.read_csv('./100 Sales Records.csv')\n",
    "pdDf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b43239",
   "metadata": {},
   "source": [
    "And guess what? We are done. This was actually so simple and easy to use. Pandas.read_csv definitely offers a lot of other parameters to tune in our data set, for example in our convertcsv.csv file, we had no column names so we can read it as"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28009c49",
   "metadata": {},
   "source": [
    "3. Pickle\n",
    " \n",
    "When your data is not in a good, human-readable format, you can use pickle to save it in a binary format. Then you can easily reload it using the pickle library.\n",
    "\n",
    "We will take our 100-Sales-Record CSV file and first save it in a pickle format so we can read it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3fbdec98",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./test.pkl','wb') as f:\n",
    "    pickle.dump(pdDf, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61587c5",
   "metadata": {},
   "source": [
    "This will create a new file test.pkl which has inside it our pdDf from Pandas heading.\n",
    "Now to open it using pickle, we just have to use pickle.load function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7255ccb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Region</th>\n",
       "      <th>Country</th>\n",
       "      <th>Item Type</th>\n",
       "      <th>Sales Channel</th>\n",
       "      <th>Order Priority</th>\n",
       "      <th>Order Date</th>\n",
       "      <th>Order ID</th>\n",
       "      <th>Ship Date</th>\n",
       "      <th>Units Sold</th>\n",
       "      <th>Unit Price</th>\n",
       "      <th>Unit Cost</th>\n",
       "      <th>Total Revenue</th>\n",
       "      <th>Total Cost</th>\n",
       "      <th>Total Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Australia and Oceania</td>\n",
       "      <td>Tuvalu</td>\n",
       "      <td>Baby Food</td>\n",
       "      <td>Offline</td>\n",
       "      <td>H</td>\n",
       "      <td>5/28/2010</td>\n",
       "      <td>669165933</td>\n",
       "      <td>6/27/2010</td>\n",
       "      <td>9925</td>\n",
       "      <td>255.28</td>\n",
       "      <td>159.42</td>\n",
       "      <td>2533654.00</td>\n",
       "      <td>1582243.50</td>\n",
       "      <td>951410.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Central America and the Caribbean</td>\n",
       "      <td>Grenada</td>\n",
       "      <td>Cereal</td>\n",
       "      <td>Online</td>\n",
       "      <td>C</td>\n",
       "      <td>8/22/2012</td>\n",
       "      <td>963881480</td>\n",
       "      <td>9/15/2012</td>\n",
       "      <td>2804</td>\n",
       "      <td>205.70</td>\n",
       "      <td>117.11</td>\n",
       "      <td>576782.80</td>\n",
       "      <td>328376.44</td>\n",
       "      <td>248406.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Europe</td>\n",
       "      <td>Russia</td>\n",
       "      <td>Office Supplies</td>\n",
       "      <td>Offline</td>\n",
       "      <td>L</td>\n",
       "      <td>5/2/2014</td>\n",
       "      <td>341417157</td>\n",
       "      <td>5/8/2014</td>\n",
       "      <td>1779</td>\n",
       "      <td>651.21</td>\n",
       "      <td>524.96</td>\n",
       "      <td>1158502.59</td>\n",
       "      <td>933903.84</td>\n",
       "      <td>224598.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sub-Saharan Africa</td>\n",
       "      <td>Sao Tome and Principe</td>\n",
       "      <td>Fruits</td>\n",
       "      <td>Online</td>\n",
       "      <td>C</td>\n",
       "      <td>6/20/2014</td>\n",
       "      <td>514321792</td>\n",
       "      <td>7/5/2014</td>\n",
       "      <td>8102</td>\n",
       "      <td>9.33</td>\n",
       "      <td>6.92</td>\n",
       "      <td>75591.66</td>\n",
       "      <td>56065.84</td>\n",
       "      <td>19525.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sub-Saharan Africa</td>\n",
       "      <td>Rwanda</td>\n",
       "      <td>Office Supplies</td>\n",
       "      <td>Offline</td>\n",
       "      <td>L</td>\n",
       "      <td>2/1/2013</td>\n",
       "      <td>115456712</td>\n",
       "      <td>2/6/2013</td>\n",
       "      <td>5062</td>\n",
       "      <td>651.21</td>\n",
       "      <td>524.96</td>\n",
       "      <td>3296425.02</td>\n",
       "      <td>2657347.52</td>\n",
       "      <td>639077.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Region                Country        Item Type  \\\n",
       "0              Australia and Oceania                 Tuvalu        Baby Food   \n",
       "1  Central America and the Caribbean                Grenada           Cereal   \n",
       "2                             Europe                 Russia  Office Supplies   \n",
       "3                 Sub-Saharan Africa  Sao Tome and Principe           Fruits   \n",
       "4                 Sub-Saharan Africa                 Rwanda  Office Supplies   \n",
       "\n",
       "  Sales Channel Order Priority Order Date   Order ID  Ship Date  Units Sold  \\\n",
       "0       Offline              H  5/28/2010  669165933  6/27/2010        9925   \n",
       "1        Online              C  8/22/2012  963881480  9/15/2012        2804   \n",
       "2       Offline              L   5/2/2014  341417157   5/8/2014        1779   \n",
       "3        Online              C  6/20/2014  514321792   7/5/2014        8102   \n",
       "4       Offline              L   2/1/2013  115456712   2/6/2013        5062   \n",
       "\n",
       "   Unit Price  Unit Cost  Total Revenue  Total Cost  Total Profit  \n",
       "0      255.28     159.42     2533654.00  1582243.50     951410.50  \n",
       "1      205.70     117.11      576782.80   328376.44     248406.36  \n",
       "2      651.21     524.96     1158502.59   933903.84     224598.75  \n",
       "3        9.33       6.92       75591.66    56065.84      19525.82  \n",
       "4      651.21     524.96     3296425.02  2657347.52     639077.50  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"test.pkl\", \"rb\") as f:\n",
    "    d4 = pickle.load(f)\n",
    "\n",
    "d4.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd973923",
   "metadata": {},
   "source": [
    "And here we have successfully loaded data from a pickle file in pandas.DataFrame format.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da64ad0",
   "metadata": {},
   "source": [
    "Learning Outcomes You are now aware of 3 different ways to load data files in Python, which can help you in different ways to load a data set when you are working in your day-to-day projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98a5ef2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
